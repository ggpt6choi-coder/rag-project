"""
Q&A ì„œë¹„ìŠ¤ - RAG (Retrieval-Augmented Generation)
ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤
"""

import requests
import json
from typing import List, Dict, Any, Optional
from loguru import logger
from src.config import config
from src.search_service import SearchService
from src.embedding_service import EmbeddingService


class QAService:
    def __init__(self):
        """Q&A ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.ollama_host = config.OLLAMA_HOST
        self.llm_model = "gemma3:latest"  # Gemma3 ëª¨ë¸ ì‚¬ìš©
        self.search_service = SearchService()
        self.embedding_service = EmbeddingService()
        
        logger.info(f"Q&A ì„œë¹„ìŠ¤ ì´ˆê¸°í™”: {self.llm_model}")
    
    def generate_answer(self, query: str, context: List[str], max_tokens: int = 500) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±"""
        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_prompt(query, context)
            
            # Ollama API í˜¸ì¶œ
            response = requests.post(
                f"{self.ollama_host}/api/generate",
                json={
                    "model": self.llm_model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "max_tokens": max_tokens
                    }
                },
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get("response", "").strip()
                logger.info(f"ë‹µë³€ ìƒì„± ì™„ë£Œ: {len(answer)}ì")
                return answer
            else:
                logger.error(f"LLM API ì˜¤ë¥˜: {response.status_code}")
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _build_prompt(self, query: str, context: List[str]) -> str:
        """RAG í”„ë¡¬í”„íŠ¸ êµ¬ì„± - ìµœì í™”ëœ ë²„ì „"""
        context_text = "\n\n".join(context)
        
        prompt = f"""ë‹¤ìŒì€ ë¬¸ì„œì—ì„œ ê²€ìƒ‰ëœ ê´€ë ¨ ë‚´ìš©ì…ë‹ˆë‹¤:

{context_text}

ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ë¬¸ì„œì— ìˆëŠ” ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì„¸ìš”.

ì§ˆë¬¸: {query}

ë‹µë³€:"""
        
        return prompt
    
    def ask_question(self, question: str, collection_name: str = "pdf_documents", 
                    max_results: int = 5, max_tokens: int = 500) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        try:
            logger.info(f"ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {question}")
            
            # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            search_results = self.search_service.search(
                query=question,
                limit=max_results
            )
            
            logger.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ")
            
            if not search_results:
                logger.warning(f"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: {question}")
                return {
                    "question": question,
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "sources": [],
                    "search_results": []
                }
            
            # 2. ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            context_texts = []
            sources = []
            
            for result in search_results:
                text = result.get("text", "")
                if text:
                    context_texts.append(text)
                    sources.append({
                        "id": result.get("id"),
                        "score": result.get("score"),
                        "document_id": result.get("document_id"),
                        "chunk_index": result.get("chunk_index")
                    })
            
            # 3. LLMì„ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„±
            answer = self.generate_answer(question, context_texts, max_tokens)
            
            return {
                "question": question,
                "answer": answer,
                "sources": sources,
                "search_results": search_results,
                "context_count": len(context_texts)
            }
            
        except Exception as e:
            logger.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "question": question,
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "sources": [],
                "search_results": [],
                "error": str(e)
            }
    
    def ask_with_metadata(self, question: str, collection_name: str = "pdf_documents") -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•œ ìƒì„¸í•œ ì§ˆë¬¸ ì²˜ë¦¬"""
        try:
            # ê¸°ë³¸ ì§ˆë¬¸ ì²˜ë¦¬
            result = self.ask_question(question, collection_name)
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ë¶„ì„
            if result.get("search_results"):
                # ë¬¸ì„œ ì •ë³´ ìˆ˜ì§‘
                documents = {}
                for search_result in result["search_results"]:
                    doc_id = search_result.get("document_id")
                    if doc_id not in documents:
                        documents[doc_id] = {
                            "document_id": doc_id,
                            "metadata": search_result.get("metadata", {}),
                            "chunks_count": 0
                        }
                    documents[doc_id]["chunks_count"] += 1
                
                result["documents"] = list(documents.values())
                
                # í†µê³„ ì •ë³´
                result["stats"] = {
                    "total_results": len(result["search_results"]),
                    "unique_documents": len(documents),
                    "avg_score": sum(r.get("score", 0) for r in result["search_results"]) / len(result["search_results"]) if result["search_results"] else 0
                }
            
            return result
            
        except Exception as e:
            logger.error(f"ë©”íƒ€ë°ì´í„° í¬í•¨ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "question": question,
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "error": str(e)
            }
    
    def test_llm_connection(self) -> bool:
        """LLM ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = requests.post(
                f"{self.ollama_host}/api/generate",
                json={
                    "model": self.llm_model,
                    "prompt": "ì•ˆë…•í•˜ì„¸ìš”. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
                    "stream": False,
                    "options": {
                        "max_tokens": 10
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                logger.info("LLM ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                return True
            else:
                logger.error(f"LLM ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"LLM ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def get_available_models(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        try:
            response = requests.get(f"{self.ollama_host}/api/tags")
            if response.status_code == 200:
                models = response.json().get("models", [])
                return [model["name"] for model in models]
            else:
                return []
        except Exception as e:
            logger.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return []


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_qa_service():
    """Q&A ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    qa_service = QAService()
    
    # LLM ì—°ê²° í…ŒìŠ¤íŠ¸
    if not qa_service.test_llm_connection():
        print("âŒ LLM ì—°ê²° ì‹¤íŒ¨")
        return
    
    print("âœ… LLM ì—°ê²° ì„±ê³µ")
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_questions = [
        "ìš´ìˆ˜ì¢‹ì€ë‚ ì— ë‚˜ì˜¤ëŠ” ë“±ì¥ì¸ë¬¼ ì´ë¦„ë“¤ì€?",
        "ê¹€ì²¨ì§€ëŠ” ì–´ë–¤ ì§ì—…ì„ ê°€ì§€ê³  ìˆë‚˜ìš”?",
        "ì¹˜ì‚¼ì€ ì–´ë–¤ ì¸ë¬¼ì¸ê°€ìš”?",
        "ê°œë˜¥ì´ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
        "ì´ ì†Œì„¤ì˜ ë°°ê²½ì€ ì–´ë””ì¸ê°€ìš”?"
    ]
    
    for question in test_questions:
        print(f"\nğŸ” ì§ˆë¬¸: {question}")
        result = qa_service.ask_question(question)
        print(f"ğŸ’¡ ë‹µë³€: {result['answer']}")
        print(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(result['search_results'])}")


if __name__ == "__main__":
    test_qa_service()
