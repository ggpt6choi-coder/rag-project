#!/usr/bin/env python3
"""
PDF to Qdrant Vector Database ì‚¬ìš© ì˜ˆì œ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê³ 
ê²€ìƒ‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

import os
import sys
import time
from pathlib import Path
import argparse

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from src.pdf_processor import PDFProcessor
from src.text_chunker import TextChunker
from src.embedding_service import EmbeddingService
from src.qdrant_manager import QdrantManager
from src.search_service import SearchService
from src.config import config

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--step', type=str, choices=['pdf', 'search', 'all'], default='all', help='ì‹¤í–‰í•  ë‹¨ê³„')
    args = parser.parse_args()

    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ PDF to Qdrant Vector Database ì˜ˆì œ")
    print("=" * 50)
    
    # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    print("ğŸ“‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    pdf_processor = PDFProcessor()
    text_chunker = TextChunker()
    embedding_service = EmbeddingService()
    qdrant_manager = QdrantManager()
    search_service = SearchService(qdrant_manager, embedding_service)
    
    # ì„œë¹„ìŠ¤ ì—°ê²° í™•ì¸
    print("ğŸ”— ì„œë¹„ìŠ¤ ì—°ê²° í™•ì¸ ì¤‘...")
    
    # Qdrant ì—°ê²° í™•ì¸
    if not qdrant_manager.connect():
        print("âŒ Qdrant ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   Dockerë¡œ Qdrantë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("   docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant")
        return
    
    print("âœ… Qdrant ì—°ê²° ì„±ê³µ")
    
    # Ollama ëª¨ë¸ í™•ì¸
    if not embedding_service.validate_model():
        print("âŒ Ollama ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   Ollamaë¥¼ ì„¤ì¹˜í•˜ê³  ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
        print("   ollama pull nomic-embed-text")
        return
    
    print("âœ… Ollama ëª¨ë¸ ê²€ì¦ ì„±ê³µ")
    
    # ìƒ˜í”Œ PDF íŒŒì¼ ê²½ë¡œ
    sample_pdf = "data/uploads/ìš´ìˆ˜ì¢‹ì€ë‚ .pdf"
    
    # ìƒ˜í”Œ PDFê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists(sample_pdf):
        print("ğŸ“„ ìƒ˜í”Œ PDF íŒŒì¼ ìƒì„± ì¤‘...")
        create_sample_pdf(sample_pdf)
    
    if not os.path.exists(sample_pdf):
        print("âŒ ìƒ˜í”Œ PDF íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“„ PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘: {sample_pdf}")
    
    try:
        # 1. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if args.step in ['pdf', 'all']:
            print("1ï¸âƒ£ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
            start_time = time.time()
            pdf_data = pdf_processor.extract_text(sample_pdf)
            extraction_time = time.time() - start_time
            
            print(f"   âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ ({extraction_time:.2f}ì´ˆ)")
            print(f"   ğŸ“„ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(pdf_data['text'])} ë¬¸ì")
            print(f"   ğŸ“Š ë©”íƒ€ë°ì´í„°: {pdf_data['metadata']}")
            
            # 2. í…ìŠ¤íŠ¸ ì²­í‚¹
            print("2ï¸âƒ£ í…ìŠ¤íŠ¸ ì²­í‚¹ ì¤‘...")
            start_time = time.time()
            chunks = text_chunker.chunk_text(pdf_data['text'])
            chunking_time = time.time() - start_time
            
            print(f"   âœ… ì²­í‚¹ ì™„ë£Œ ({chunking_time:.2f}ì´ˆ)")
            print(f"   ğŸ“¦ ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}")
            
            # ì²­í¬ í†µê³„ ì¶œë ¥
            stats = text_chunker.get_chunk_statistics(chunks)
            print(f"   ğŸ“Š ì²­í¬ í†µê³„: í‰ê·  {stats['avg_chunk_size']:.1f} ë¬¸ì")
            
            # 3. ì„ë² ë”© ìƒì„±
            print("3ï¸âƒ£ ì„ë² ë”© ìƒì„± ì¤‘...")
            start_time = time.time()
            embedded_chunks = embedding_service.embed_chunks(chunks)
            embedding_time = time.time() - start_time
            
            print(f"   âœ… ì„ë² ë”© ì™„ë£Œ ({embedding_time:.2f}ì´ˆ)")
            print(f"   ğŸ§  ì„ë² ë”© ì°¨ì›: {embedded_chunks[0]['embedding_dimension'] if embedded_chunks else 0}")
            
            # 4. Qdrantì— ì €ì¥
            print("4ï¸âƒ£ Qdrantì— ì €ì¥ ì¤‘...")
            start_time = time.time()
            document_id = "example_document"
            success = qdrant_manager.store_vectors(embedded_chunks, document_id)
            storage_time = time.time() - start_time
            
            if success:
                print(f"   âœ… ì €ì¥ ì™„ë£Œ ({storage_time:.2f}ì´ˆ)")
                print(f"   ğŸ“Š ì €ì¥ëœ ë²¡í„° ìˆ˜: {len(embedded_chunks)}")
            else:
                print("   âŒ ì €ì¥ ì‹¤íŒ¨")
                return

        # 5. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        if args.step in ['search', 'all']:
            print("5ï¸âƒ£ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì¤‘...")
            test_queries = ["ê¹€ì²œì§€", "ì¸ë ¥ê±°"]
            
            for query in test_queries:
                print(f"   ğŸ” ê²€ìƒ‰: '{query}'")
                start_time = time.time()
                results = search_service.search(query, limit=3)
                search_time = time.time() - start_time
                
                print(f"      âœ… ê²€ìƒ‰ ì™„ë£Œ ({search_time:.3f}ì´ˆ)")
                print(f"      ğŸ“Š ê²°ê³¼ ìˆ˜: {len(results)}")
                
                if results:
                    best_result = results[0]
                    print(f"      ğŸ† ìµœê³  ì ìˆ˜: {best_result['score']:.3f}")
                    print(f"      ğŸ“„ í…ìŠ¤íŠ¸: {best_result['text'][:100]}...")
        
        # 6. ì»¬ë ‰ì…˜ ì •ë³´ ì¶œë ¥
        print("6ï¸âƒ£ ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸ ì¤‘...")
        collection_info = search_service.get_collection_info()
        if collection_info:
            print(f"   ğŸ“Š ìƒíƒœ: {collection_info['status']}")
            print(f"   ğŸ§  ë²¡í„° ìˆ˜: {collection_info['vectors_count']}")
            print(f"   ğŸ“¦ í¬ì¸íŠ¸ ìˆ˜: {collection_info['points_count']}")
        
        print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\në‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ API ì„œë²„ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        print("python src/main.py")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

def create_sample_pdf(file_path):
    """ìƒ˜í”Œ PDF íŒŒì¼ ìƒì„±"""
    try:
        from reportlab.pdfgen import canvas
        from reportlab.lib.pagesizes import letter
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        # PDF ìƒì„±
        c = canvas.Canvas(file_path, pagesize=letter)
        
        # ì œëª©
        c.setFont("Helvetica-Bold", 16)
        c.drawString(100, 750, "ì¸ê³µì§€ëŠ¥ê³¼ ë¨¸ì‹ ëŸ¬ë‹")
        
        # ë¶€ì œëª©
        c.setFont("Helvetica", 12)
        c.drawString(100, 720, "ìƒ˜í”Œ ë¬¸ì„œ")
        
        # ë³¸ë¬¸
        c.setFont("Helvetica", 10)
        text = """
ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ì—¬ í•™ìŠµí•˜ê³ , ì¶”ë¡ í•˜ê³ , 
ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ë¡œ, 
ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ë”¥ëŸ¬ë‹ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•˜ìœ„ ë¶„ì•¼ë¡œ, ì¸ê³µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ íŒ¨í„´ì„ 
í•™ìŠµí•©ë‹ˆë‹¤. ìì—°ì–´ ì²˜ë¦¬, ì»´í“¨í„° ë¹„ì „, ìŒì„± ì¸ì‹ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ 
í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.

ë°ì´í„° ë¶„ì„ì€ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. 
í†µê³„ì  ë°©ë²•ê³¼ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì˜ íŒ¨í„´ì„ ë°œê²¬í•˜ê³  
ì˜ì‚¬ê²°ì •ì— í™œìš©í•©ë‹ˆë‹¤.
        """
        
        y_position = 680
        for line in text.strip().split('\n'):
            c.drawString(100, y_position, line.strip())
            y_position -= 15
        
        c.save()
        print(f"   âœ… ìƒ˜í”Œ PDF ìƒì„± ì™„ë£Œ: {file_path}")
        
    except ImportError:
        print("   âš ï¸ reportlabì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ìƒ˜í”Œ PDFë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   pip install reportlabë¡œ ì„¤ì¹˜í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ PDF íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"   âŒ ìƒ˜í”Œ PDF ìƒì„± ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main()
