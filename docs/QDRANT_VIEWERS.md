# Qdrant ë°ì´í„° ì‹œê°í™” ë„êµ¬ë“¤

Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë„êµ¬ë“¤ì„ ì†Œê°œí•©ë‹ˆë‹¤.

## ğŸ” í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤

### 1. **ì§ì ‘ HTTP API í™•ì¸** (ê°€ì¥ ì•ˆì •ì )
```bash
# ì»¬ë ‰ì…˜ ëª©ë¡ í™•ì¸
curl -s http://localhost:6333/collections | jq .

# íŠ¹ì • ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
curl -s http://localhost:6333/collections/pdf_documents | jq .

# í¬ì¸íŠ¸ ë°ì´í„° ì¡°íšŒ
curl -s -X POST "http://localhost:6333/collections/pdf_documents/points/scroll" \
  -H "Content-Type: application/json" \
  -d '{"limit": 10, "with_payload": true, "with_vectors": false}' | jq .
```

### 2. **Python ìŠ¤í¬ë¦½íŠ¸ ë„êµ¬ë“¤**

#### A. ê°„ë‹¨í•œ ë°ì´í„° í™•ì¸ (`check_qdrant_data.py`)
```bash
# ì „ì²´ ë°ì´í„° í™•ì¸
python check_qdrant_data.py
```

**ê¸°ëŠ¥:**
- ğŸ“Š ì»¬ë ‰ì…˜ ëª©ë¡ í‘œì‹œ
- ğŸ“‹ ì»¬ë ‰ì…˜ ìƒì„¸ ì •ë³´
- ğŸ” í¬ì¸íŠ¸ ë°ì´í„° ì¡°íšŒ
- ğŸ† ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
- ğŸ“„ JSON í˜•íƒœë¡œ ì „ì²´ ì •ë³´ ì¶œë ¥

#### B. ê³ ê¸‰ ë·°ì–´ (`qdrant_viewer.py`)
```bash
# ì»¬ë ‰ì…˜ ëª©ë¡
python qdrant_viewer.py --action collections

# ì»¬ë ‰ì…˜ ìƒì„¸ ì •ë³´
python qdrant_viewer.py --action info --collection pdf_documents

# í¬ì¸íŠ¸ ë°ì´í„° ì¡°íšŒ
python qdrant_viewer.py --action points --collection pdf_documents --limit 5

# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
python qdrant_viewer.py --action search --collection pdf_documents --query "ì¸ê³µì§€ëŠ¥"
```

**ê¸°ëŠ¥:**
- ğŸ“Š í…Œì´ë¸” í˜•íƒœë¡œ ë°ì´í„° í‘œì‹œ
- ğŸ” ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥
- ğŸ“‹ í˜ì´ë¡œë“œ ìƒì„¸ ë¶„ì„
- ğŸ¯ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì˜µì…˜

## ğŸŒ ì›¹ ê¸°ë°˜ ë„êµ¬ë“¤

### 1. **Qdrant Web UI** (ê³µì‹ - ì œí•œì )
```bash
# Dockerë¡œ ì‹¤í–‰ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
docker run -d --name qdrant-web-ui -p 8080:80 qdrant/qdrant-web-ui
```

### 2. **Jupyter Notebook ê¸°ë°˜ ë·°ì–´**
```python
# Jupyterì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ
import requests
import pandas as pd
import matplotlib.pyplot as plt
from qdrant_client import QdrantClient

# ë°ì´í„° ë¡œë“œ
client = QdrantClient("localhost", port=6333)
collections = client.get_collections()

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
data = []
for collection in collections.collections:
    info = client.get_collection(collection.name)
    data.append({
        'name': collection.name,
        'points_count': info.points_count,
        'vector_size': info.config.params.vectors.size,
        'distance': info.config.params.vectors.distance
    })

df = pd.DataFrame(data)
print(df)
```

### 3. **Streamlit ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ**
```python
# streamlit_qdrant_viewer.py
import streamlit as st
import requests
import pandas as pd

def main():
    st.title("Qdrant ë°ì´í„° ë·°ì–´")
    
    # ì»¬ë ‰ì…˜ ëª©ë¡
    response = requests.get("http://localhost:6333/collections")
    collections = response.json()["result"]["collections"]
    
    st.header("ì»¬ë ‰ì…˜ ëª©ë¡")
    for collection in collections:
        st.write(f"- {collection['name']}")
    
    # ì„ íƒëœ ì»¬ë ‰ì…˜ì˜ ë°ì´í„° í‘œì‹œ
    selected_collection = st.selectbox("ì»¬ë ‰ì…˜ ì„ íƒ", [c['name'] for c in collections])
    
    if selected_collection:
        # í¬ì¸íŠ¸ ë°ì´í„° ì¡°íšŒ
        scroll_url = f"http://localhost:6333/collections/{selected_collection}/points/scroll"
        response = requests.post(scroll_url, json={"limit": 100, "with_payload": True})
        
        if response.status_code == 200:
            points = response.json()["result"]["points"]
            st.write(f"ì´ {len(points)}ê°œ í¬ì¸íŠ¸")
            
            # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ
            data = []
            for point in points:
                data.append({
                    'ID': point['id'],
                    'Text': point['payload'].get('text', '')[:100] + '...',
                    'Document ID': point['payload'].get('document_id', ''),
                    'Chunk Index': point['payload'].get('chunk_index', ''),
                    'Page Number': point['payload'].get('page_number', '')
                })
            
            df = pd.DataFrame(data)
            st.dataframe(df)

if __name__ == "__main__":
    main()
```

## ğŸ“Š ë°ì´í„° ë¶„ì„ ë„êµ¬ë“¤

### 1. **ë²¡í„° ì‹œê°í™”**
```python
# ë²¡í„°ë¥¼ 2Dë¡œ ì‹œê°í™”
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

def visualize_vectors(collection_name="pdf_documents"):
    # ë²¡í„° ë°ì´í„° ìˆ˜ì§‘
    response = requests.post(
        f"http://localhost:6333/collections/{collection_name}/points/scroll",
        json={"limit": 1000, "with_vectors": True, "with_payload": True}
    )
    
    points = response.json()["result"]["points"]
    vectors = np.array([point["vector"] for point in points])
    
    # PCAë¡œ 2D ë³€í™˜
    pca = PCA(n_components=2)
    vectors_2d = pca.fit_transform(vectors)
    
    # ì‹œê°í™”
    plt.figure(figsize=(10, 8))
    plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], alpha=0.6)
    plt.title("Qdrant ë²¡í„° ë¶„í¬ (PCA)")
    plt.xlabel("ì²« ë²ˆì§¸ ì£¼ì„±ë¶„")
    plt.ylabel("ë‘ ë²ˆì§¸ ì£¼ì„±ë¶„")
    plt.show()
```

### 2. **í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„**
```python
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

def analyze_clusters(collection_name="pdf_documents", n_clusters=5):
    # ë²¡í„° ë°ì´í„° ìˆ˜ì§‘
    response = requests.post(
        f"http://localhost:6333/collections/{collection_name}/points/scroll",
        json={"limit": 1000, "with_vectors": True}
    )
    
    points = response.json()["result"]["points"]
    vectors = np.array([point["vector"] for point in points])
    
    # K-means í´ëŸ¬ìŠ¤í„°ë§
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(vectors)
    
    # ì‹¤ë£¨ì—£ ì ìˆ˜ ê³„ì‚°
    silhouette_avg = silhouette_score(vectors, clusters)
    
    print(f"í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}")
    print(f"ì‹¤ë£¨ì—£ ì ìˆ˜: {silhouette_avg:.3f}")
    
    # í´ëŸ¬ìŠ¤í„°ë³„ í¬ì¸íŠ¸ ìˆ˜
    for i in range(n_clusters):
        count = np.sum(clusters == i)
        print(f"í´ëŸ¬ìŠ¤í„° {i}: {count}ê°œ í¬ì¸íŠ¸")
```

## ğŸ› ï¸ ì»¤ìŠ¤í…€ ë„êµ¬ ê°œë°œ

### 1. **FastAPI ê¸°ë°˜ ì›¹ ë·°ì–´**
```python
# web_viewer.py
from fastapi import FastAPI, HTTPException
from fastapi.responses import HTMLResponse
import requests

app = FastAPI()

@app.get("/", response_class=HTMLResponse)
async def qdrant_viewer():
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>Qdrant ë°ì´í„° ë·°ì–´</title>
        <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    </head>
    <body>
        <h1>Qdrant ë°ì´í„° ë·°ì–´</h1>
        <div id="collections"></div>
        <div id="data"></div>
        <script>
            // JavaScriptë¡œ ë°ì´í„° ë¡œë“œ ë° ì‹œê°í™”
            fetch('/api/collections')
                .then(response => response.json())
                .then(data => {
                    document.getElementById('collections').innerHTML = 
                        '<h2>ì»¬ë ‰ì…˜: ' + data.collections.join(', ') + '</h2>';
                });
        </script>
    </body>
    </html>
    """
    return html_content

@app.get("/api/collections")
async def get_collections():
    response = requests.get("http://localhost:6333/collections")
    return response.json()
```

### 2. **CLI ë„êµ¬**
```python
# cli_viewer.py
import click
import requests
from tabulate import tabulate

@click.group()
def cli():
    """Qdrant ë°ì´í„° ë·°ì–´ CLI"""
    pass

@cli.command()
def list_collections():
    """ì»¬ë ‰ì…˜ ëª©ë¡ í‘œì‹œ"""
    response = requests.get("http://localhost:6333/collections")
    collections = response.json()["result"]["collections"]
    
    table_data = []
    for collection in collections:
        table_data.append([collection["name"]])
    
    print(tabulate(table_data, headers=["ì»¬ë ‰ì…˜ëª…"], tablefmt="grid"))

@cli.command()
@click.argument("collection_name")
def show_collection(collection_name):
    """ì»¬ë ‰ì…˜ ìƒì„¸ ì •ë³´ í‘œì‹œ"""
    response = requests.get(f"http://localhost:6333/collections/{collection_name}")
    info = response.json()["result"]
    
    print(f"ì»¬ë ‰ì…˜: {collection_name}")
    print(f"í¬ì¸íŠ¸ ìˆ˜: {info['points_count']}")
    print(f"ë²¡í„° ì°¨ì›: {info['config']['params']['vectors']['size']}")

if __name__ == "__main__":
    cli()
```

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ë„êµ¬ë“¤

### 1. **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**
```python
# monitor.py
import time
import requests
from datetime import datetime

def monitor_qdrant():
    while True:
        try:
            response = requests.get("http://localhost:6333/collections")
            collections = response.json()["result"]["collections"]
            
            print(f"[{datetime.now()}] Qdrant ìƒíƒœ:")
            for collection in collections:
                info_response = requests.get(f"http://localhost:6333/collections/{collection['name']}")
                info = info_response.json()["result"]
                print(f"  {collection['name']}: {info['points_count']} í¬ì¸íŠ¸")
            
            time.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬
        except Exception as e:
            print(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
            time.sleep(60)
```

### 2. **ì„±ëŠ¥ ë¶„ì„**
```python
# performance_analyzer.py
import time
import requests
import statistics

def analyze_search_performance(collection_name="pdf_documents", queries=10):
    times = []
    
    for i in range(queries):
        start_time = time.time()
        
        # ê²€ìƒ‰ ìš”ì²­
        response = requests.post(
            f"http://localhost:6333/collections/{collection_name}/points/search",
            json={"vector": [0.1] * 768, "limit": 5}
        )
        
        end_time = time.time()
        times.append(end_time - start_time)
    
    print(f"í‰ê·  ê²€ìƒ‰ ì‹œê°„: {statistics.mean(times):.3f}ì´ˆ")
    print(f"ìµœì†Œ ê²€ìƒ‰ ì‹œê°„: {min(times):.3f}ì´ˆ")
    print(f"ìµœëŒ€ ê²€ìƒ‰ ì‹œê°„: {max(times):.3f}ì´ˆ")
```

## ğŸ¯ ì¶”ì²œ ì‚¬ìš©ë²•

### 1. **ì¼ë°˜ì ì¸ ë°ì´í„° í™•ì¸**
```bash
# ê°€ì¥ ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì¸ ë°©ë²•
python check_qdrant_data.py
```

### 2. **ìƒì„¸ ë¶„ì„**
```bash
# ê³ ê¸‰ ê¸°ëŠ¥ ì‚¬ìš©
python qdrant_viewer.py --action collections
python qdrant_viewer.py --action info --collection pdf_documents
python qdrant_viewer.py --action points --collection pdf_documents --limit 10
```

### 3. **ì›¹ ê¸°ë°˜ í™•ì¸**
```bash
# Streamlit ëŒ€ì‹œë³´ë“œ (ì¶”ê°€ ì„¤ì¹˜ í•„ìš”)
pip install streamlit
streamlit run streamlit_qdrant_viewer.py
```

### 4. **CLI ë„êµ¬**
```bash
# CLI ë„êµ¬ ì‚¬ìš©
python cli_viewer.py list-collections
python cli_viewer.py show-collection pdf_documents
```

## ğŸ”§ ì„¤ì¹˜ ë° ì„¤ì •

### í•„ìš”í•œ íŒ¨í‚¤ì§€
```bash
pip install requests tabulate pandas matplotlib scikit-learn streamlit click
```

### í™˜ê²½ ì„¤ì •
```bash
# Qdrant ì„œë²„ í™•ì¸
curl http://localhost:6333/collections

# í¬íŠ¸ í™•ì¸
lsof -i :6333
```

## ğŸ“ ì‚¬ìš© íŒ

1. **ë°ì´í„° ë°±ì—…**: ì¤‘ìš”í•œ ë°ì´í„°ëŠ” ì •ê¸°ì ìœ¼ë¡œ ë°±ì—…
2. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ì˜ ê²½ìš° ì„±ëŠ¥ ì§€í‘œ í™•ì¸
3. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ë²¡í„° ë°ì´í„°ëŠ” ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ì£¼ì˜
4. **ì¸ë±ì‹± ìƒíƒœ**: `indexed_vectors_count` í™•ì¸ìœ¼ë¡œ ì¸ë±ì‹± ìƒíƒœ ì²´í¬

## ğŸš€ ê³ ê¸‰ ê¸°ëŠ¥

### 1. **ë²¡í„° ìœ ì‚¬ë„ ë¶„ì„**
```python
def analyze_similarity(collection_name="pdf_documents"):
    # ëª¨ë“  ë²¡í„° ê°„ ìœ ì‚¬ë„ ê³„ì‚°
    response = requests.post(
        f"http://localhost:6333/collections/{collection_name}/points/scroll",
        json={"limit": 100, "with_vectors": True}
    )
    
    points = response.json()["result"]["points"]
    vectors = np.array([point["vector"] for point in points])
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    from sklearn.metrics.pairwise import cosine_similarity
    similarity_matrix = cosine_similarity(vectors)
    
    print(f"í‰ê·  ìœ ì‚¬ë„: {np.mean(similarity_matrix):.3f}")
    print(f"ìµœëŒ€ ìœ ì‚¬ë„: {np.max(similarity_matrix):.3f}")
    print(f"ìµœì†Œ ìœ ì‚¬ë„: {np.min(similarity_matrix):.3f}")
```

### 2. **ë°ì´í„° í’ˆì§ˆ ë¶„ì„**
```python
def analyze_data_quality(collection_name="pdf_documents"):
    response = requests.post(
        f"http://localhost:6333/collections/{collection_name}/points/scroll",
        json={"limit": 1000, "with_payload": True}
    )
    
    points = response.json()["result"]["points"]
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„ì„
    text_lengths = [len(point["payload"].get("text", "")) for point in points]
    
    print(f"í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´: {statistics.mean(text_lengths):.1f}")
    print(f"ìµœì†Œ í…ìŠ¤íŠ¸ ê¸¸ì´: {min(text_lengths)}")
    print(f"ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´: {max(text_lengths)}")
```

ì´ëŸ¬í•œ ë„êµ¬ë“¤ì„ í™œìš©í•˜ì—¬ Qdrantì— ì €ì¥ëœ ë²¡í„° ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™•ì¸í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ‰
